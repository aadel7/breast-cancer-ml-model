{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML Coursework assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wisconsin Diagnostic Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wisconsin Diagnostic Breast Cancer dataset describes the measurements on cells in suspicious lumps in a women's breast. This dataset, obtained from the University of Wisconsin Hospitals, includes 30 feature variables and 1 target variable. \n",
    "\n",
    "The features, or input attributes, are numeric, and a binary target variable: M for Malignant and B for benign.\n",
    "\n",
    "Each cell-nucleus include 10 actual features:\n",
    "\n",
    "- Radius (mean of distances from center to points on the perimeter)\n",
    "- Texture (standard deviation of gray-scale values)\n",
    "- Perimeter\n",
    "- Area\n",
    "- Smoothness (local variation in radius lengths)\n",
    "- Compactness (perimeter^2 / area - 1.0)\n",
    "- Concavity (severity of concave portions of the contour)\n",
    "- Concave points (number of concave portions of the contour)\n",
    "- Symmetry \n",
    "- Fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "Now, we will load the dataset so we can check the data in detail. To do so, we'll install the required libraries and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install matplotlib pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "\n",
    "data_combined = pd.concat([X, y], axis=1)\n",
    "  \n",
    "# metadata \n",
    "#print(breast_cancer_wisconsin_diagnostic.metadata) \n",
    "  \n",
    "# variable information \n",
    "#print(breast_cancer_wisconsin_diagnostic.variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll retrieve a data preview of the data so we can have a first look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the data\n",
    "print(\"\\nFirst few rows of Features and Target combined\")\n",
    "print(data_combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dimensionality of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we're able to access the repository from UCIML and the data is loaded. Now we need to understand the dimensionality of the dataset in terms of number of rows, columns (features and target variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the data\n",
    "\n",
    "print(\"Shape of X (features):\", X.shape)\n",
    "print(\"Shape of y (targets):\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve the statistical properties of each attribute in order to get some insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "descriptionDataCombined = data_combined.describe()\n",
    "\n",
    "print(descriptionDataCombined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a classification problem, we need to analyse the data in order to check how many observations do we have for each class. If they are highly imbalanced, then we'll need to take further actions in the data pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = data_combined.groupby('Diagnosis').size()\n",
    "print(class_counts)\n",
    "\n",
    "total = class_counts.sum()\n",
    "proportion_B = class_counts['B'] / total\n",
    "proportion_M = class_counts['M'] / total\n",
    "\n",
    "print(f\"\\nProportion of class B: {proportion_B:.2f}\")\n",
    "print(f\"Proportion of class M: {proportion_M:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calculating the correlation between the different variables we'll be able to analyse if they are tightly coupled (highly correlated). This is important as it can affect the performance of the machine learning algorithms.\n",
    "\n",
    "Let's calculate the Pearson's Correlation Coefficient, assuming that we have a normal distribution in the attributes. Before that, we need to convert the target variable to a numeric one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Diagnosis column from string to numerical values.\n",
    "data_combined['Diagnosis'] = data_combined['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Calculate the Pearson's Correlation Coefficient\n",
    "correlations = data_combined.corr(method='pearson')\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the table size is big, let's retrieve those variables that are highly correlated (> 0.75) by sorting and printing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack the correlation matrix\n",
    "correlation_pairs = correlations.unstack()\n",
    "\n",
    "# Sort the correlation pairs\n",
    "sorted_pairs = correlation_pairs.sort_values(kind=\"quicksort\", ascending=False)\n",
    "\n",
    "# Retrieve high correlations and exclude self-correlations, as they aren't relevant.\n",
    "high_correlations = sorted_pairs[(sorted_pairs != 1.0) & (sorted_pairs.abs() > 0.75)]\n",
    "\n",
    "print(high_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a correlation matrix to achieve a better understanding of the data correlation\n",
    "\n",
    "Datasource: https://stackoverflow.com/questions/29432629/plot-correlation-matrix-using-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Correlation Matrix\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(correlations, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar(label='Correlation')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.xticks(range(len(correlations.columns)), correlations.columns, rotation=90)\n",
    "plt.yticks(range(len(correlations.index)), correlations.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the highly correlated variables are the radius and perimeter. This makes sense due to its mathematical relationship, as the radius is directly proportional to the perimeter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
